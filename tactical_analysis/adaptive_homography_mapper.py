"""Adaptive Homography Mapper for Moving Camera Soccer Analysis.

Builds per-frame homographies with intelligent fallbacks for tactical
camera recordings with panning/zooming motion.

STABILITY ENHANCEMENTS (SoccerNet Best Practices):
- Normalization transform for numerical stability (SoccerNet baseline)
- PnP refinement with Levenberg-Marquardt optimization
- Temporal homography smoothing (EMA) to prevent matrix instability
- Position validation with bounds checking
- Per-player position smoothing to reduce jitter
- Homography validation before use
"""

import sys
from pathlib import Path

PROJECT_DIR = Path(__file__).resolve().parent.parent
sys.path.append(str(PROJECT_DIR))

from collections import defaultdict, deque
from typing import Dict, List, Optional, Tuple

import cv2
import numpy as np
import supervision as sv

from tactical_analysis.calibration_utils import (
    estimate_homography_normalized, refine_homography_pnp, validate_homography)
from tactical_analysis.sports_compat import SoccerPitchConfiguration


class AdaptiveHomographyMapper:
    """
    Per-frame homography with temporal fallbacks for moving cameras.

    Handles tactical camera recordings with continuous panning by:
    1. Building homography per frame when sufficient features detected
    2. Interpolating from nearby frames when features insufficient
    3. Using camera motion compensation for temporal coherence
    4. Falling back to proportional scaling as last resort
    """

    def __init__(self, field_dimensions: Tuple[float, float] = (105, 68),
                 min_keypoints: int = 4, temporal_window: int = 15,
                 ema_alpha: float = 0.3, max_matrix_change: float = 50.0,
                 position_smoothing_buffer: int = 3):
        """
        Initialize adaptive homography mapper with stability features.

        Args:
            field_dimensions: (width, height) in meters (default: FIFA standard)
            min_keypoints: Minimum keypoints required for homography (must be >= 4)
            temporal_window: Frames to search for temporal fallback
            ema_alpha: EMA smoothing weight for new matrices (0.3 = 30% new, 70% previous)
            max_matrix_change: Maximum allowed matrix element change (reject if exceeded)
            position_smoothing_buffer: Number of positions to buffer per player for smoothing
        """
        self.field_width = field_dimensions[0]
        self.field_height = field_dimensions[1]
        self.min_keypoints = max(4, min_keypoints)  # Ensure at least 4 for homography
        self.temporal_window = temporal_window

        # STABILITY PARAMETERS
        self.ema_alpha = ema_alpha  # Lower = more smoothing (0.2-0.4 recommended)
        self.max_matrix_change = max_matrix_change  # Reject extreme changes
        self.position_smoothing_buffer = position_smoothing_buffer

        # Initialize pitch configuration with 32 dense keypoints
        self.CONFIG = SoccerPitchConfiguration()

        # Get all 32 pitch reference points
        self.all_pitch_points = np.array(self.CONFIG.vertices, dtype=np.float32)

        # Per-frame storage
        self.frame_homographies = {}  # {frame_idx: matrix}
        self.frame_keypoints = {}  # {frame_idx: [(pixel_x, pixel_y, pitch_x, pitch_y)]}
        self.frame_confidences = {}  # {frame_idx: confidence_score}

        # TEMPORAL SMOOTHING STORAGE
        self.H_previous = None  # Last stable homography matrix
        self.H_smooth = None    # Current smoothed homography
        self.H_buffer = deque(maxlen=5)  # Buffer of recent matrices for median filtering

        # PER-PLAYER POSITION SMOOTHING
        self.player_position_buffers = {}  # {player_id: deque of positions}

        # Statistics
        self.total_frames_processed = 0
        self.homography_success_count = 0
        self.temporal_fallback_count = 0
        self.proportional_fallback_count = 0
        self.matrix_rejected_count = 0  # New: Count unstable matrices rejected

        # SHOT BOUNDARIES (for scene change detection)
        self.shot_boundaries = []  # List of frame indices where camera shots change
        self.shot_boundary_set = set()  # Set for fast lookup

    def set_shot_boundaries(self, shot_boundaries: List[int]):
        """
        Set camera shot boundaries for improved homography stability.

        When a shot boundary is detected (camera cut/transition), the homography
        smoothing is reset to avoid carrying over incorrect transformation matrices
        from the previous camera angle.

        Args:
            shot_boundaries: List of frame indices where camera shots change
        """
        self.shot_boundaries = shot_boundaries
        self.shot_boundary_set = set(shot_boundaries)
        print(f"[Adaptive Homography] Set {len(shot_boundaries)} shot boundaries for scene-aware processing")

    def add_frame_data(self, frame_idx: int, keypoints: 'sv.KeyPoints'):
        """
        Add detected keypoints for a frame.

        ROBOFLOW/SPORTS APPROACH:
        Uses sv.KeyPoints object with .xy property and applies mask to BOTH
        source and target simultaneously to maintain index alignment.

        Args:
            frame_idx: Frame index
            keypoints: sv.KeyPoints object from sv.KeyPoints.from_ultralytics()
        """
        self.total_frames_processed += 1

        if keypoints is None or len(keypoints) == 0:
            self.frame_keypoints[frame_idx] = []
            return

        # ROBOFLOW PATTERN: Use keypoints.xy[0] to get coordinates
        # This matches their exact implementation!
        mask = (keypoints.xy[0][:, 0] > 1) & (keypoints.xy[0][:, 1] > 1)

        # DEBUG: Log keypoint statistics for first 5 frames
        if frame_idx <= 5:
            total_kp = len(keypoints.xy[0])
            num_valid = np.sum(mask)
            print(f"[Adaptive Homography] Frame {frame_idx} DEBUG: "
                  f"Total keypoints: {total_kp}, Spatially valid (x>1,y>1): {num_valid}")

        # Apply mask to BOTH source and target (exact roboflow pattern)
        valid_pixel_points = keypoints.xy[0][mask].astype(np.float32)
        valid_pitch_points = np.array(self.CONFIG.vertices)[mask].astype(np.float32)

        # Get confidence if available
        if hasattr(keypoints, 'confidence') and keypoints.confidence is not None:
            valid_confidences = keypoints.confidence[0][mask]
        else:
            valid_confidences = np.ones(len(valid_pixel_points))

        # Combine for storage
        combined_keypoints = []
        for i in range(len(valid_pixel_points)):
            x, y = valid_pixel_points[i]
            pitch_x, pitch_y = valid_pitch_points[i]
            conf = valid_confidences[i]
            combined_keypoints.append((x, y, pitch_x, pitch_y, conf))

        # Store keypoints
        self.frame_keypoints[frame_idx] = combined_keypoints

        # Try to build homography for this frame
        if len(combined_keypoints) >= self.min_keypoints:
            success = self._build_frame_homography(frame_idx, combined_keypoints)
            if success:
                self.homography_success_count += 1
                # Log first 5 successes to verify it's working
                if self.homography_success_count <= 5:
                    print(f"[Adaptive Homography] Frame {frame_idx}: ‚úì Built homography from {len(combined_keypoints)} keypoints")
        else:
            # Log first 5 failures AND sample every 100 frames to see pattern
            if self.total_frames_processed <= 5 or frame_idx % 100 == 0:
                print(f"[Adaptive Homography] Frame {frame_idx}: Insufficient keypoints "
                      f"({len(combined_keypoints)}/{self.min_keypoints})")

    def _get_yolo_keypoint_mapping(self, kp_idx: int) -> Optional[int]:
        """
        Map YOLO keypoint index (32 keypoints) to pitch point index (35 points).

        The mapping ensures YOLO detected keypoints correspond to the correct
        pitch reference points from our 35-point configuration.
        """
        # Mapping from 32 YOLO keypoints to 35 pitch points (0-indexed)
        mapping = np.array([
            0,   # 0 -> Point 1 (top-left corner)
            1,   # 1 -> Point 2 (left penalty area top)
            2,   # 2 -> Point 3 (left goal area top)
            3,   # 3 -> Point 4 (left goal area bottom)
            4,   # 4 -> Point 5 (left penalty area bottom)
            5,   # 5 -> Point 6 (bottom-left corner)
            6,   # 6 -> Point 7 (left goal box top-right)
            7,   # 7 -> Point 8 (left goal box bottom-right)
            8,   # 8 -> Point 9 (left penalty spot)
            9,   # 9 -> Point 10 (left penalty box top-right)
            10,  # 10 -> Point 11
            11,  # 11 -> Point 12
            12,  # 12 -> Point 13 (left penalty box bottom-right)
            13,  # 13 -> Point 14 (center line top)
            14,  # 14 -> Point 15 (center circle top)
            15,  # 15 -> Point 16 (center circle bottom)
            16,  # 16 -> Point 17 (center line bottom)
            17,  # 17 -> Point 18 (right penalty box top-left)
            18,  # 18 -> Point 19
            19,  # 19 -> Point 20
            20,  # 20 -> Point 21 (right penalty box bottom-left)
            21,  # 21 -> Point 22 (right penalty spot)
            22,  # 22 -> Point 23 (right goal box top-left)
            23,  # 23 -> Point 24 (right goal box bottom-left)
            24,  # 24 -> Point 25 (top-right corner)
            25,  # 25 -> Point 26 (right penalty area top)
            26,  # 26 -> Point 27 (right goal area top)
            27,  # 27 -> Point 28 (right goal area bottom)
            28,  # 28 -> Point 29 (right penalty area bottom)
            29,  # 29 -> Additional keypoint (placeholder)
            30,  # 30 -> Additional keypoint (placeholder)
            31,  # 31 -> Additional keypoint (placeholder)
        ])
        if kp_idx < len(mapping):
            return int(mapping[kp_idx])
        return None

    def _build_frame_homography(self, frame_idx: int, keypoints: List[Tuple]) -> bool:
        """
        Build homography matrix for a single frame WITH SOCCERNET ENHANCEMENTS.

        Implements SoccerNet best practices + stability improvements:
        1. Normalization transform for numerical stability (SoccerNet baseline)
        2. Homography validation before use
        3. Optional PnP refinement for accuracy
        4. Matrix change validation (reject extreme changes)
        5. Exponential moving average (EMA) smoothing
        6. Fallback to previous stable matrix if new one is unstable

        Args:
            frame_idx: Frame index
            keypoints: List of (pixel_x, pixel_y, pitch_x, pitch_y, confidence)

        Returns:
            True if successful, False otherwise
        """
        if len(keypoints) < self.min_keypoints:
            return False

        # Extract pixel and pitch points
        pixel_points = []
        pitch_points = []

        for kp in keypoints:
            pixel_points.append([kp[0], kp[1]])
            pitch_points.append([kp[2], kp[3]])

        pixel_points = np.array(pixel_points, dtype=np.float32)
        pitch_points = np.array(pitch_points, dtype=np.float32)

        try:
            # ROBOFLOW/SPORTS EXACT MATCH: Use cv2.findHomography with default parameters
            # They use: self.m, _ = cv2.findHomography(source, target)
            # This automatically uses RANSAC with threshold=3.0 when >4 points
            H_raw, mask = cv2.findHomography(
                pixel_points,
                pitch_points
            )

            # Check if we have enough inliers after RANSAC
            if mask is not None and len(mask) > 0:
                num_inliers = np.sum(mask)
                inlier_ratio = num_inliers / len(mask)

                # Log RANSAC results for first 10 frames to diagnose issues
                if frame_idx <= 10:
                    print(f"[Adaptive Homography] Frame {frame_idx} RANSAC: "
                          f"{num_inliers}/{len(mask)} inliers ({inlier_ratio:.1%})")

                # Require at least 50% inliers and minimum 4 inliers
                if num_inliers < 4 or inlier_ratio < 0.5:
                    if frame_idx < 5 or frame_idx % 100 == 0:
                        print(f"[Adaptive Homography] Frame {frame_idx}: Too few inliers "
                              f"({num_inliers}/{len(mask)}, {inlier_ratio:.1%})")
                    return False

            # Validate homography exists
            if H_raw is None:
                if frame_idx <= 10:
                    print(f"[Adaptive Homography] Frame {frame_idx}: H_raw is None")
                return False

            # ROBOFLOW/SPORTS: No validation - just use the homography!
            # They trust RANSAC to filter outliers, validation often rejects good matrices
            # due to coordinate system differences (cm vs pixels vs normalized)

            # SOCCERNET ENHANCEMENT: Optional PnP refinement for better accuracy
            # Only refine if we have good keypoint coverage
            if len(keypoints) >= 8:  # Need reasonable number for refinement
                pitch_3d = np.c_[pitch_points, np.zeros(len(pitch_points))]
                H_refined = refine_homography_pnp(
                    H_raw,
                    pixel_points,
                    pitch_3d,
                    image_size=(1920, 1080),
                    max_iterations=20000
                )
                if H_refined is not None:
                    H_raw = H_refined

            num_keypoints = len(keypoints)

            # CHECK FOR SHOT BOUNDARY: Reset smoothing if this is a new camera shot
            is_shot_boundary = frame_idx in self.shot_boundary_set
            if is_shot_boundary:
                # Reset temporal smoothing at shot boundaries
                self.H_previous = None
                self.H_smooth = None
                self.H_buffer.clear()
                if frame_idx < 10 or frame_idx % 50 == 0:  # Log some boundaries
                    print(f"[Adaptive Homography] Frame {frame_idx}: üé¨ Shot boundary detected - resetting temporal smoothing")

            # STEP 1: Add to buffer for MEDIAN FILTERING (like BallTracker)
            self.H_buffer.append(H_raw)

            # Apply median filtering if we have enough history
            if len(self.H_buffer) >= 3:
                # Use median of last 3-5 matrices to remove outliers
                H_median = np.median(self.H_buffer, axis=0)
            else:
                H_median = H_raw

            # STEP 2: Check if this is first frame or detect scene changes
            if self.H_previous is None:
                # First frame - no smoothing possible
                H_candidate = H_median
                self.H_smooth = H_median
                matrix = H_median  # ‚Üê FIX: Set matrix variable for first frame
                confidence = 1.0

                if frame_idx < 3:
                    print(f"[Adaptive Homography] Frame {frame_idx}: ‚úì Built initial homography from {num_keypoints} keypoints (SoccerNet enhanced)")
            else:
                # Calculate difference from previous frame (using median-filtered matrix)
                max_diff_raw = np.abs(H_median - self.H_previous).max()

                # ADAPTIVE SMOOTHING: Graduated alpha based on change magnitude
                is_scene_change = False
                should_reject = False

                if max_diff_raw > 1000:
                    # CATASTROPHIC change - likely bad detection
                    if num_keypoints >= 20:
                        # Even with good keypoints, use VERY aggressive smoothing
                        is_scene_change = True
                        alpha = 0.02  # 2% new, 98% old - extreme smoothing

                        if self.matrix_rejected_count < 10 or frame_idx % 100 == 0:
                            print(f"[Adaptive Homography] Frame {frame_idx}: üé¨ CATASTROPHIC change "
                                  f"(diff: {max_diff_raw:.1f}, {num_keypoints} keypoints) - using alpha={alpha}")
                    else:
                        # Bad detection - reject
                        should_reject = True

                        if self.matrix_rejected_count < 10 or frame_idx % 100 == 0:
                            print(f"[Adaptive Homography] Frame {frame_idx}: ‚ö†Ô∏è REJECTED catastrophic "
                                  f"(diff: {max_diff_raw:.1f}, only {num_keypoints} keypoints)")

                elif max_diff_raw > 400:
                    # VERY LARGE change - use very aggressive smoothing
                    if num_keypoints >= 20:
                        is_scene_change = True
                        alpha = 0.05  # 5% new, 95% old

                        if self.matrix_rejected_count < 10 or frame_idx % 100 == 0:
                            print(f"[Adaptive Homography] Frame {frame_idx}: üé¨ Very large change "
                                  f"(diff: {max_diff_raw:.1f}) - using alpha={alpha}")
                    else:
                        should_reject = True

                        if self.matrix_rejected_count < 10 or frame_idx % 100 == 0:
                            print(f"[Adaptive Homography] Frame {frame_idx}: ‚ö†Ô∏è REJECTED large change "
                                  f"(diff: {max_diff_raw:.1f}, only {num_keypoints} keypoints)")

                elif max_diff_raw > 200:
                    # LARGE change (like frame 528-529) - use aggressive smoothing
                    if num_keypoints >= 20:
                        is_scene_change = True
                        alpha = 0.08  # 8% new, 92% old - MUCH MORE AGGRESSIVE

                        # DEBUG: Always log frames 200-220 to catch Player 19/20 jumps
                        if frame_idx < 10 or (self.homography_success_count < 20 and is_scene_change) or (200 <= frame_idx <= 220):
                            print(f"[Adaptive Homography] Frame {frame_idx}: üé¨ Large change "
                                  f"(diff: {max_diff_raw:.1f}, {num_keypoints} keypoints) - using alpha={alpha}")
                    else:
                        should_reject = True

                        if self.matrix_rejected_count < 10 or frame_idx % 100 == 0 or (200 <= frame_idx <= 220):
                            print(f"[Adaptive Homography] Frame {frame_idx}: ‚ö†Ô∏è REJECTED medium change "
                                  f"(diff: {max_diff_raw:.1f}, only {num_keypoints} keypoints)")
                else:
                    # Normal frame - use slow, stable smoothing
                    alpha = 0.10  # 10% new, 90% old for normal frames (was 0.2)

                if should_reject:
                    # Reject this frame - keep previous matrix
                    self.matrix_rejected_count += 1
                    matrix = self.H_previous.copy()
                    confidence = 0.7

                    # Store and continue (don't update H_previous)
                    self.frame_homographies[frame_idx] = matrix
                    self.frame_confidences[frame_idx] = confidence
                    return True

                # STEP 3: Apply EMA smoothing with adaptive alpha
                H_candidate = alpha * H_median + (1.0 - alpha) * self.H_previous
                self.H_smooth = H_candidate

                # Calculate difference AFTER smoothing
                max_diff_smooth = np.abs(H_candidate - self.H_previous).max()

                # FINAL SAFETY CHECK: Adaptive threshold based on change magnitude
                if max_diff_raw > 1000:
                    # Catastrophic changes - very strict even after smoothing
                    safety_threshold = 100  # With alpha=0.05, smoothed should be ~50
                elif max_diff_raw > 400:
                    # Very large changes - moderate threshold
                    safety_threshold = 60   # With alpha=0.1, smoothed should be ~40
                elif max_diff_raw > 200:
                    # Large changes - lenient threshold
                    safety_threshold = 40   # With alpha=0.15, smoothed should be ~30
                else:
                    # Normal frames - strict threshold
                    safety_threshold = 20   # With alpha=0.2, should be very small

                if max_diff_smooth > safety_threshold:
                    # Even after median + EMA, change is too large - reject
                    self.matrix_rejected_count += 1

                    # DEBUG: Always log frames 200-220 rejections
                    if self.matrix_rejected_count < 10 or frame_idx % 100 == 0 or (200 <= frame_idx <= 220):
                        print(f"[Adaptive Homography] Frame {frame_idx}: ‚ö†Ô∏è REJECTED - still unstable after smoothing "
                              f"(raw: {max_diff_raw:.1f} ‚Üí smooth: {max_diff_smooth:.1f} > threshold: {safety_threshold}) "
                              f"- keeping previous")

                    matrix = self.H_previous.copy()
                    confidence = 0.6

                    # Store and continue
                    self.frame_homographies[frame_idx] = matrix
                    self.frame_confidences[frame_idx] = confidence
                    return True

                # Accept smoothed matrix
                matrix = H_candidate
                confidence = 0.9 if is_scene_change else 1.0

                # Log first 5 successful smoothings or scene changes
                if self.homography_success_count < 5 or is_scene_change:
                    if is_scene_change:
                        print(f"[Adaptive Homography] Frame {frame_idx}: ‚úì Scene change smoothed "
                              f"(raw: {max_diff_raw:.1f} ‚Üí smooth: {max_diff_smooth:.1f}, alpha: {alpha})")
                    else:
                        print(f"[Adaptive Homography] Frame {frame_idx}: ‚úì EMA smoothed "
                              f"(diff: {max_diff_smooth:.1f}, alpha: {alpha})")

            # Update previous matrix for next frame comparison
            self.H_previous = matrix.copy()

            # SUCCESS - Store the smoothed homography matrix
            self.frame_homographies[frame_idx] = matrix
            self.frame_confidences[frame_idx] = confidence

            return True

        except Exception as e:
            print(f"[Adaptive Homography] Frame {frame_idx}: Homography failed - {e}")
            return False

    def transform_point(self, frame_idx: int, pixel_coord: np.ndarray,
                       camera_motion: Optional[Tuple[float, float]] = None) -> Tuple[np.ndarray, str, float]:
        """
        Transform pixel coordinate to field coordinate with fallbacks.

        Multi-tier strategy:
        1. Use frame homography if available
        2. Interpolate from nearby frames
        3. Use proportional scaling

        Args:
            frame_idx: Frame index
            pixel_coord: (x, y) in pixels
            camera_motion: Optional (dx, dy) camera movement

        Returns:
            Tuple of (field_coord, method, confidence)
        """
        # Compensate for camera motion first
        if camera_motion is not None:
            pixel_coord = pixel_coord.copy()
            pixel_coord[0] -= camera_motion[0]
            pixel_coord[1] -= camera_motion[1]

        # Tier 1: Per-frame homography
        if frame_idx in self.frame_homographies:
            matrix = self.frame_homographies[frame_idx]
            confidence = self.frame_confidences.get(frame_idx, 0.5)
            field_coord = self._apply_homography(pixel_coord, matrix)

            if field_coord is not None:
                return field_coord, 'per-frame', confidence

        # Tier 2: Temporal interpolation from nearby frames
        field_coord, conf = self._temporal_interpolation(frame_idx, pixel_coord)
        if field_coord is not None:
            self.temporal_fallback_count += 1
            return field_coord, 'temporal', conf

        # Tier 3: Proportional scaling fallback
        self.proportional_fallback_count += 1
        field_coord = self._proportional_scaling(pixel_coord)
        return field_coord, 'proportional', 0.3

    def _apply_homography(self, pixel_coord: np.ndarray, matrix: np.ndarray) -> Optional[np.ndarray]:
        """Apply homography transformation to a point with validation."""
        try:
            point = np.array([[pixel_coord]], dtype=np.float32)
            transformed = cv2.perspectiveTransform(point, matrix)
            field_coord = transformed[0][0]

            # Convert from pitch units (12000 x 7000 cm) to meters
            field_coord[0] = field_coord[0] * (self.field_width / 12000.0)
            field_coord[1] = field_coord[1] * (self.field_height / 7000.0)

            # CRITICAL VALIDATION: Reject results that are wildly out of bounds
            # Allow some margin (50m) for edge detection, but reject extreme outliers
            if (field_coord[0] < -50 or field_coord[0] > 155 or
                field_coord[1] < -50 or field_coord[1] > 118):
                # This transformation is corrupted - return None to trigger fallback
                return None

            return field_coord
        except:
            return None

    def validate_position(self, position: np.ndarray, previous_position: Optional[np.ndarray] = None,
                         dt: float = 0.04, max_speed_ms: float = 12.5) -> Tuple[bool, str]:
        """
        Validate transformed position for physical plausibility.

        Args:
            position: Current position [x, y] in meters
            previous_position: Previous position [x, y] in meters (optional)
            dt: Time delta between frames (default: 0.04s for 25fps)
            max_speed_ms: Maximum allowed speed in m/s (default: 12.5 m/s = 45 km/h)

        Returns:
            Tuple of (is_valid, reason)
        """
        # Bounds check with 10m safety margin
        if not (-10 <= position[0] <= self.field_width + 10 and
                -10 <= position[1] <= self.field_height + 10):
            return False, f"out_of_bounds ({position[0]:.1f}, {position[1]:.1f})"

        # Distance check if we have previous position
        if previous_position is not None:
            distance = np.linalg.norm(position - previous_position)
            max_distance = max_speed_ms * dt  # e.g., 12.5 m/s * 0.04s = 0.5m per frame

            if distance > max_distance:
                implied_speed_kmh = (distance / dt) * 3.6
                return False, f"impossible_jump ({distance:.2f}m = {implied_speed_kmh:.0f} km/h)"

        return True, "valid"

    def smooth_player_position(self, player_id: int, position_raw: np.ndarray) -> np.ndarray:
        """
        Apply per-player position smoothing using median filter.

        Similar to Roboflow's BallTracker but for all players.

        Args:
            player_id: Unique player/tracker ID
            position_raw: Raw transformed position [x, y]

        Returns:
            Smoothed position [x, y]
        """
        if player_id not in self.player_position_buffers:
            self.player_position_buffers[player_id] = deque(maxlen=self.position_smoothing_buffer)

        # Add to buffer
        self.player_position_buffers[player_id].append(position_raw)

        # Return median of buffered positions
        if len(self.player_position_buffers[player_id]) >= 2:
            positions = np.array(self.player_position_buffers[player_id])
            return np.median(positions, axis=0)
        else:
            # Not enough history - return raw
            return position_raw

    def _temporal_interpolation(self, frame_idx: int, pixel_coord: np.ndarray) -> Tuple[Optional[np.ndarray], float]:
        """
        Interpolate transformation from nearby frames.

        Args:
            frame_idx: Current frame index
            pixel_coord: Pixel coordinate to transform

        Returns:
            Tuple of (field_coord, confidence) or (None, 0.0)
        """
        # Find nearest frames with valid homography
        nearby_frames = []
        for offset in range(1, self.temporal_window + 1):
            # Check before
            prev_frame = frame_idx - offset
            if prev_frame in self.frame_homographies:
                nearby_frames.append((prev_frame, offset))

            # Check after
            next_frame = frame_idx + offset
            if next_frame in self.frame_homographies:
                nearby_frames.append((next_frame, offset))

            # Stop if we found at least 2
            if len(nearby_frames) >= 2:
                break

        if not nearby_frames:
            return None, 0.0

        # Use closest frame
        nearby_frames.sort(key=lambda x: x[1])
        closest_frame, distance = nearby_frames[0]

        matrix = self.frame_homographies[closest_frame]
        field_coord = self._apply_homography(pixel_coord, matrix)

        if field_coord is not None:
            # Reduce confidence based on temporal distance
            base_conf = self.frame_confidences.get(closest_frame, 0.5)
            confidence = base_conf * np.exp(-distance / 10.0)  # Exponential decay
            return field_coord, float(confidence)

        return None, 0.0

    def _proportional_scaling(self, pixel_coord: np.ndarray,
                            video_dimensions: Tuple[int, int] = (1280, 720)) -> np.ndarray:
        """
        Conservative proportional scaling fallback.

        Args:
            pixel_coord: Pixel coordinate
            video_dimensions: Video (width, height)

        Returns:
            Field coordinate in meters
        """
        video_width, video_height = video_dimensions

        # Assume field occupies central 60% of frame (conservative)
        field_visible_fraction = 0.6
        margin = (1 - field_visible_fraction) / 2

        # Normalize
        norm_x = (pixel_coord[0] / video_width - margin) / field_visible_fraction
        norm_y = (pixel_coord[1] / video_height - margin) / field_visible_fraction

        # Clamp to [0, 1]
        norm_x = np.clip(norm_x, 0, 1)
        norm_y = np.clip(norm_y, 0, 1)

        # Scale to field dimensions
        field_coord = np.array([
            norm_x * self.field_width,
            norm_y * self.field_height
        ], dtype=np.float32)

        return field_coord

    def get_statistics(self) -> Dict:
        """Get processing statistics including stability metrics."""
        return {
            'total_frames_processed': self.total_frames_processed,
            'frames_with_homography': len(self.frame_homographies),
            'homography_success_rate': (
                self.homography_success_count / self.total_frames_processed
                if self.total_frames_processed > 0 else 0.0
            ),
            'temporal_fallback_count': self.temporal_fallback_count,
            'proportional_fallback_count': self.proportional_fallback_count,
            'matrix_rejected_count': self.matrix_rejected_count,  # NEW
            'matrix_rejection_rate': (
                self.matrix_rejected_count / self.total_frames_processed
                if self.total_frames_processed > 0 else 0.0
            ),  # NEW
            'smoothing_active': self.H_smooth is not None,  # NEW
        }

    def print_statistics(self):
        """Print processing statistics including stability metrics."""
        stats = self.get_statistics()
        print(f"\n[Adaptive Homography] Statistics:")
        print(f"  Total frames processed: {stats['total_frames_processed']}")
        print(f"  Frames with homography: {stats['frames_with_homography']}")
        print(f"  Success rate: {100*stats['homography_success_rate']:.1f}%")
        print(f"  Temporal fallbacks: {stats['temporal_fallback_count']}")
        print(f"  Proportional fallbacks: {stats['proportional_fallback_count']}")
        print(f"  Unstable matrices rejected: {stats['matrix_rejected_count']} "
              f"({100*stats['matrix_rejection_rate']:.1f}%)")  # NEW
        print(f"  EMA smoothing active: {stats['smoothing_active']}")  # NEW
